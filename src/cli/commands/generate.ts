import { existsSync, mkdirSync, readFileSync, writeFileSync } from 'node:fs'
import { dirname } from 'node:path'
import chalk from 'chalk'
import * as yaml from 'js-yaml'
import ora from 'ora'
import { generateMockWithAI, generateTestWithAI } from '../../ai/agents/index'
import { TestGenerationPipeline } from '../../ai/generation/test-generation-pipeline'
import { generateTestDataFiles } from '../../ai/utils/test-data-generator'
import {
  findStateMachine,
  loadProjectConfig,
  loadStateMachineDefinition,
  resolveMockPath,
  resolveTestSuitePath,
} from '../../config/loader'
import {
  DEFAULT_ASL_FILENAME,
  DEFAULT_CONFIG_FILE,
  DEFAULT_MOCK_FILENAME,
  DEFAULT_TEST_DATA_DIR,
  DEFAULT_TEST_FILENAME,
} from '../../constants/defaults'
import type { StateMachineConfig } from '../../schemas/config-schema'
import { type MockConfig, mockConfigSchema } from '../../schemas/mock-schema'
import { type JsonObject, StateFactory, type StateMachine } from '../../types/asl'
import { isError } from '../../types/type-guards'
import { extractStateMachineFromCDK } from '../../utils/cdk-extractor'
import { processInParallel } from '../../utils/parallel'

/**
 * Safe file write with automatic directory creation
 */
function safeWriteFileSync(filePath: string, content: string): void {
  const dir = dirname(filePath)

  if (!existsSync(dir)) {
    mkdirSync(dir, { recursive: true })
  }

  writeFileSync(filePath, content)
}

// Adapter function to bridge generateTestWithAI to TestGenerationPipeline
function createTestGeneratorAdapter(
  aiModel: string,
  timeoutMs: number,
): (prompt: string, stateMachine: StateMachine, options?: JsonObject) => Promise<string> {
  return async (
    _prompt: string,
    stateMachine: StateMachine,
    options?: JsonObject,
  ): Promise<string> => {
    return await generateTestWithAI(
      stateMachine,
      aiModel,
      timeoutMs,
      options?.mockContent as string | undefined,
      options?.mockFile as string | undefined,
      options?.aslFile as string | undefined,
      options?.outputPath as string | undefined,
    )
  }
}

interface GenerateOptions {
  name?: string
  asl?: string
  cdk?: string
  /** CDK„ÉÜ„É≥„Éó„É¨„Éº„ÉàÂÜÖ„ÅÆÁâπÂÆö„ÅÆ„Çπ„ÉÜ„Éº„Éà„Éû„Ç∑„É≥„ÇíÊåáÂÆö */
  cdkStateMachine?: string
  output?: string
  aiModel: string
  timeout?: string
  /** For test generation, use existing mock file */
  mock?: string
  /** Maximum attempts for generation cycle */
  maxAttempts?: string
  /** Maximum concurrent AI generation operations */
  concurrency?: string
  /** Enable verbose output */
  verbose?: boolean
}

// Helper function to ensure data is not undefined
function ensureStateMachineData(data: JsonObject | undefined): JsonObject {
  if (!data) {
    throw new Error('State machine data is required')
  }
  return data
}

export async function generateCommand(
  type: string,
  options: GenerateOptions,
  cmd?: { parent?: () => { opts?: () => { config?: string } } },
): Promise<void> {
  const spinner = ora(`Generating ${type}...`).start()

  try {
    let stateMachine: JsonObject | undefined
    let stateMachineInstance: StateMachine | undefined
    let defaultOutputPath: string | undefined
    let configAslFileName: string | undefined
    let configMockFileName: string | undefined
    let outputPath: string = ''
    let testDataPath: string = DEFAULT_TEST_DATA_DIR

    // --name „Ç™„Éó„Ç∑„Éß„É≥„ÅåÊåáÂÆö„Åï„Çå„ÅüÂ†¥Âêà„ÄÅË®≠ÂÆö„Éï„Ç°„Ç§„É´„Åã„ÇâË™≠„ÅøËæº„Åø„ÇíË©¶„Åø„Çã
    if (options.name) {
      const parentOpts = cmd?.parent as { opts(): { config?: string } } | undefined
      const configPath = parentOpts?.opts()?.config || DEFAULT_CONFIG_FILE
      const config = loadProjectConfig(configPath, false)

      // Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÅåÂ≠òÂú®„Åó„ÄÅ„Åã„Å§--name„Åå„Çπ„ÉÜ„Éº„Éà„Éû„Ç∑„É≥Âêç„Å®„Åó„Å¶Ë¶ã„Å§„Åã„ÇãÂ†¥Âêà
      if (config) {
        testDataPath = config?.paths?.testData || DEFAULT_TEST_DATA_DIR
        const stateMachineConfig = findStateMachine(config, options.name)

        if (stateMachineConfig) {
          spinner.text = `Loading state machine '${options.name}' from configuration...`
          stateMachine = loadStateMachineDefinition(stateMachineConfig)

          // „Éï„Ç°„Ç§„É´Âêç„ÇíË®≠ÂÆö„Åã„ÇâÂèñÂæó
          configAslFileName = stateMachineConfig.source.path.split('/').pop() || 'workflow.asl.json'
          configMockFileName = `${options.name}.mock.yaml`

          // „Éá„Éï„Ç©„É´„Éà„ÅÆÂá∫Âäõ„Éë„Çπ„ÇíË®≠ÂÆö
          if (!options.output) {
            defaultOutputPath =
              type === 'mock'
                ? resolveMockPath(config, options.name)
                : resolveTestSuitePath(config, options.name)
          }
        }
      }

      // Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÅåÂ≠òÂú®„Åó„Å™„ÅÑ„ÄÅ„Åæ„Åü„ÅØË®≠ÂÆöÂÜÖ„Å´„Çπ„ÉÜ„Éº„Éà„Éû„Ç∑„É≥„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØ
      // --name„Çí„Éï„Ç°„Ç§„É´Âêç„ÅÆ„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ„Å®„Åó„Å¶‰ΩøÁî®„Åô„ÇãÔºàÂæåÁ∂ö„ÅÆÂá¶ÁêÜ„Å´‰ªª„Åõ„ÇãÔºâ
    }
    // ÂºïÊï∞„Å™„Åó„ÅÆÂ†¥Âêà„ÅÆ„Éá„Éï„Ç©„É´„ÉàÂãï‰ΩúÔºàrun„Ç≥„Éû„É≥„Éâ„Å®ÂêåÊßò„ÅÆËá™ÂãïÈÅ∏ÊäûÊ©üËÉΩÔºâ
    else if (!(options.asl || options.cdk)) {
      const parentOpts = cmd?.parent as { opts(): { config?: string } } | undefined
      const configPath = parentOpts?.opts()?.config || DEFAULT_CONFIG_FILE
      const config = loadProjectConfig(configPath, false)

      if (config?.stateMachines && config.stateMachines.length === 1) {
        // „Çπ„ÉÜ„Éº„Éà„Éû„Ç∑„É≥„Åå1„Å§„Å†„ÅëÂÆöÁæ©„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØËá™ÂãïÈÅ∏Êäû
        const sm = config.stateMachines[0]
        if (!sm) {
          throw new Error('No state machine configuration found')
        }
        spinner.text = `Auto-selected state machine: ${sm.name}`
        stateMachine = loadStateMachineDefinition(sm)

        // „Éï„Ç°„Ç§„É´Âêç„ÇíË®≠ÂÆö„Åã„ÇâÂèñÂæó
        configAslFileName = sm.source.path.split('/').pop() || 'workflow.asl.json'
        configMockFileName = `${sm.name}.mock.yaml`

        // „Éá„Éï„Ç©„É´„Éà„ÅÆÂá∫Âäõ„Éë„Çπ„ÇíË®≠ÂÆö
        if (!options.output) {
          defaultOutputPath =
            type === 'mock'
              ? resolveMockPath(config, sm.name)
              : resolveTestSuitePath(config, sm.name)
        }
      } else if (config?.stateMachines && config.stateMachines.length > 1) {
        // Ë§áÊï∞„ÅÇ„ÇãÂ†¥Âêà„ÅØ‰∏¶ÂàóÂÆüË°å„Åæ„Åü„ÅØÈ†ÜÊ¨°ÂÆüË°å
        const parsedConcurrency = options.concurrency ? Number.parseInt(options.concurrency, 10) : 1
        const concurrency =
          Number.isNaN(parsedConcurrency) || parsedConcurrency < 1 ? 1 : parsedConcurrency // ÁÑ°Âäπ„Å™ÂÄ§„ÅÆÂ†¥Âêà„ÅØ1„Å´„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ
        const mode = concurrency > 1 ? 'parallel' : 'sequential'

        spinner.text = `Processing ${config.stateMachines.length} state machines ${mode === 'parallel' ? `(concurrency: ${concurrency})` : '(sequential)'}...`

        const results = await processInParallel(
          config.stateMachines,
          async (sm: StateMachineConfig, index: number) => {
            const progressText = `${sm.name} (${index + 1}/${config.stateMachines.length})`
            if (mode === 'sequential') {
              spinner.text = `Processing state machine: ${progressText}`
            }

            const currentStateMachineObj = loadStateMachineDefinition(sm)
            // Use StateFactory to properly create a StateMachine with all nested states
            const currentStateMachine = StateFactory.createStateMachine(currentStateMachineObj)
            const currentConfigMockFileName = `${sm.name}.mock.yaml`

            const currentDefaultOutputPath =
              type === 'mock'
                ? resolveMockPath(config, sm.name)
                : resolveTestSuitePath(config, sm.name)

            let result: string
            switch (type) {
              case 'mock': {
                const maxAttempts = options.maxAttempts
                  ? Number.parseInt(options.maxAttempts, 10)
                  : 2
                result = await generateMockWithAI(
                  currentStateMachine, // Pass StateMachine directly (already has State instances)
                  options.aiModel,
                  options.timeout ? Number.parseInt(options.timeout, 10) : 300000,
                  maxAttempts,
                )
                break
              }
              case 'test': {
                let mockContent: string | undefined
                let mockConfig: MockConfig | undefined
                let mockFileName: string | undefined

                const autoMockPath = resolveMockPath(config, sm.name)
                if (existsSync(autoMockPath)) {
                  try {
                    mockContent = readFileSync(autoMockPath, 'utf-8')
                    const rawConfig = yaml.load(mockContent)
                    mockConfig = mockConfigSchema.parse(rawConfig)
                    mockFileName = autoMockPath
                  } catch (_err) {
                    // „Ç®„É©„Éº„ÅÆÂ†¥Âêà„ÅØÈùô„Åã„Å´ÁÑ°Ë¶ñÔºà„É¢„ÉÉ„ÇØ„Å™„Åó„ÅßÁ∂öË°åÔºâ
                  }
                }

                if (mockConfig) {
                  // Use TestGenerationPipeline for execution-based validation and correction
                  const generator = createTestGeneratorAdapter(
                    options.aiModel,
                    options.timeout ? Number.parseInt(options.timeout, 10) : 300000,
                  )
                  const pipeline = new TestGenerationPipeline(generator)
                  const pipelineResult = await pipeline.generateTest({
                    stateMachine: currentStateMachine,
                    maxAttempts: options.maxAttempts ? Number.parseInt(options.maxAttempts, 10) : 2,
                    mockFile: mockFileName ? `${sm.name}.mock.yaml` : currentConfigMockFileName,
                    aslFile: sm.name,
                    timeout: options.timeout ? Number.parseInt(options.timeout, 10) : undefined,
                    enableExecutionValidation: true,
                    mockConfig,
                    basePath: testDataPath,
                    verbose: options.verbose,
                  })

                  result = pipelineResult.content

                  // Log corrections if any were made
                  if (
                    pipelineResult.executionCorrections &&
                    pipelineResult.executionCorrections.length > 0
                  ) {
                    console.log(
                      chalk.cyan(
                        `\n‚ú® Improved ${pipelineResult.executionCorrections.length} test expectation(s) through execution validation`,
                      ),
                    )
                    if (options.verbose) {
                      pipelineResult.executionCorrections.forEach((correction) => {
                        console.log(
                          chalk.gray(
                            `  ‚Ä¢ ${correction.testCase} - ${correction.state}: ${correction.reason}`,
                          ),
                        )
                      })
                    }
                  }
                } else {
                  // Fallback to static generation without execution validation
                  const aslPath = sm.name
                  const mockPath = mockFileName ? `${sm.name}.mock.yaml` : currentConfigMockFileName

                  result = await generateTestWithAI(
                    currentStateMachine, // Pass StateMachine directly (already has State instances)
                    options.aiModel,
                    options.timeout ? Number.parseInt(options.timeout, 10) : 300000,
                    mockContent,
                    mockPath,
                    aslPath,
                    currentDefaultOutputPath,
                  )
                }
                break
              }
              default:
                throw new Error(`Unknown generation type: ${type}`)
            }

            safeWriteFileSync(currentDefaultOutputPath, result)

            if (type === 'mock' && currentStateMachine) {
              try {
                const dataFiles = generateTestDataFiles(currentStateMachine, result)
                if (dataFiles.length > 0 && options.verbose) {
                  console.log(
                    chalk.cyan(
                      `\nüì¶ Generated ${dataFiles.length} test data file(s) for ItemReader:`,
                    ),
                  )
                  dataFiles.forEach((file) => {
                    console.log(chalk.green(`  ‚úì ${file.path} (${file.format})`))
                  })
                }
              } catch (error) {
                if (mode === 'sequential') {
                  console.warn(chalk.yellow('‚ö†Ô∏è Could not generate test data files:', error))
                }
              }
            }

            return {
              stateMachine: sm,
              outputPath: currentDefaultOutputPath,
              result,
            }
          },
          concurrency,
        )

        let successCount = 0
        let failureCount = 0

        for (let i = 0; i < results.length; i++) {
          const result = results[i]
          const sm = config.stateMachines[i]

          if (!sm) {
            console.error(chalk.red(`‚úó State machine at index ${i} is undefined`))
            failureCount++
            continue
          }

          if (isError(result)) {
            console.error(
              chalk.red(`‚úó Failed to generate ${type} for ${sm.name}: ${result.message}`),
            )
            failureCount++
          } else if (result) {
            console.log(chalk.green(`‚úì Generated ${type} for ${sm.name}: ${result.outputPath}`))
            successCount++
          } else {
            console.error(chalk.red(`‚úó No result returned for ${sm.name}`))
            failureCount++
          }
        }

        const totalSummary = `Completed ${successCount + failureCount}/${config.stateMachines.length} state machines`
        const resultSummary =
          successCount > 0 && failureCount === 0
            ? chalk.green(`${totalSummary} (all succeeded)`)
            : successCount > 0 && failureCount > 0
              ? chalk.yellow(`${totalSummary} (${successCount} succeeded, ${failureCount} failed)`)
              : chalk.red(`${totalSummary} (all failed)`)

        spinner.succeed(resultSummary)
        return
      }
    }

    if (!stateMachine) {
      if (options.asl) {
        const content = readFileSync(options.asl, 'utf-8')
        stateMachine = JSON.parse(content)
      } else if (options.cdk) {
        spinner.text = 'Extracting state machine from CDK output...'
        const cdkContent = readFileSync(options.cdk, 'utf-8')
        const cdkTemplate = JSON.parse(cdkContent)
        stateMachine = extractStateMachineFromCDK(cdkTemplate, {
          stateMachineName: options.cdkStateMachine,
          verbose: options.verbose,
        })
      } else if (options.name) {
        // „Ç®„É©„Éº„Çícatch„Éñ„É≠„ÉÉ„ÇØ„ÅßÂá¶ÁêÜ„Åô„Çã„Åü„ÇÅ„ÄÅ„Åì„Åì„Åßthrow
        throw new Error(`State machine "${options.name}" not found in configuration`)
      } else {
        // „Ç®„É©„Éº„Çícatch„Éñ„É≠„ÉÉ„ÇØ„ÅßÂá¶ÁêÜ„Åô„Çã„Åü„ÇÅ„ÄÅ„Åì„Åì„Åßthrow
        throw new Error('Either --name, --asl, or --cdk option is required')
      }
    }

    let result: string
    switch (type) {
      case 'mock': {
        spinner.text = 'Generating mock configuration with AI...'
        const maxAttempts = options.maxAttempts ? Number.parseInt(options.maxAttempts, 10) : 2
        if (maxAttempts > 1) {
          spinner.text = `Generating mock with up to ${maxAttempts} attempts...`
        }
        stateMachineInstance = StateFactory.createStateMachine(ensureStateMachineData(stateMachine))
        result = await generateMockWithAI(
          stateMachineInstance, // Pass StateMachine directly
          options.aiModel,
          options.timeout ? Number.parseInt(options.timeout, 10) : 300000,
          maxAttempts,
        )
        break
      }
      case 'test': {
        spinner.text = 'Generating test cases with AI...'
        let mockContent: string | undefined
        let mockConfig: MockConfig | undefined
        let mockFileName: string | undefined

        // --mock„Ç™„Éó„Ç∑„Éß„É≥„ÅåÊòéÁ§∫ÁöÑ„Å´ÊåáÂÆö„Åï„Çå„ÅüÂ†¥Âêà
        if (options.mock) {
          try {
            mockContent = readFileSync(options.mock, 'utf-8')
            const rawConfig = yaml.load(mockContent)
            mockConfig = mockConfigSchema.parse(rawConfig)
            // Keep the full path for correct relative path calculation
            mockFileName = options.mock
            spinner.text = 'Generating test cases with AI using provided mock...'
          } catch (_err) {
            console.warn(
              chalk.yellow(
                `Warning: Could not read mock file ${options.mock}, generating without it`,
              ),
            )
          }
        }
        // --name„Ç™„Éó„Ç∑„Éß„É≥„ÅåÊåáÂÆö„Åï„Çå„ÄÅ--mock„ÅåÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà„ÅØËá™ÂãïÊ§úÁ¥¢
        else if (options.name && !options.mock) {
          const parentOpts2 = cmd?.parent as { opts(): { config?: string } } | undefined
          const configPath2 = parentOpts2?.opts()?.config || DEFAULT_CONFIG_FILE
          const config = loadProjectConfig(configPath2, false)
          if (config) {
            const autoMockPath = resolveMockPath(config, options.name)
            if (existsSync(autoMockPath)) {
              try {
                mockContent = readFileSync(autoMockPath, 'utf-8')
                const rawConfig = yaml.load(mockContent)
                mockConfig = mockConfigSchema.parse(rawConfig)
                mockFileName = autoMockPath
                spinner.text = `Generating test cases with AI using auto-detected mock: ${autoMockPath}...`
                if (options.verbose) {
                  console.log(chalk.gray(`  Auto-detected mock file: ${autoMockPath}`))
                }
              } catch (_err) {
                // „Ç®„É©„Éº„ÅÆÂ†¥Âêà„ÅØÈùô„Åã„Å´ÁÑ°Ë¶ñÔºà„É¢„ÉÉ„ÇØ„Å™„Åó„ÅßÁ∂öË°åÔºâ
              }
            }
          }
        }

        // „Éë„ÇπÊÉÖÂ†±„ÅÆÊ±∫ÂÆöÔºönameÊåáÂÆö„ÅÆÂ†¥Âêà„ÅØÂêçÂâç„Çí‰ΩøÁî®„ÄÅ„Åù„Çå‰ª•Â§ñ„ÅØ„Éë„Çπ„Çí‰ΩøÁî®
        // options„Åã„ÇâÊ∏°„Åï„Çå„Åü„Éë„Çπ„ÅØ„Åù„ÅÆ„Åæ„Åæ‰ΩøÁî®ÔºàÁõ∏ÂØæ„Éë„Çπ„Åæ„Åü„ÅØÁµ∂ÂØæ„Éë„ÇπÔºâ
        const aslPath =
          options.asl || (options.name ? options.name : configAslFileName) || DEFAULT_ASL_FILENAME
        const mockPath =
          options.mock ||
          (options.name && mockFileName ? `${options.name}.mock.yaml` : mockFileName) ||
          (options.name ? `${options.name}.mock.yaml` : configMockFileName)

        // Âá∫Âäõ„Éë„Çπ„ÇíÂÖà„Å´Ê±∫ÂÆöÔºàgenerateTestWithAI„Å´Ê∏°„Åô„Åü„ÇÅÔºâ
        outputPath =
          options.output ||
          defaultOutputPath ||
          (type === 'test' ? DEFAULT_TEST_FILENAME : DEFAULT_MOCK_FILENAME)

        stateMachineInstance = StateFactory.createStateMachine(ensureStateMachineData(stateMachine))

        if (mockConfig) {
          // Use TestGenerationPipeline for execution-based validation and correction
          spinner.text = 'Generating and validating test cases with execution-based correction...'
          const generator = createTestGeneratorAdapter(
            options.aiModel,
            options.timeout ? Number.parseInt(options.timeout, 10) : 300000,
          )
          const pipeline = new TestGenerationPipeline(generator)
          const pipelineResult = await pipeline.generateTest({
            stateMachine: stateMachineInstance,
            maxAttempts: options.maxAttempts ? Number.parseInt(options.maxAttempts, 10) : 2,
            mockFile: mockPath,
            aslFile: aslPath,
            timeout: options.timeout ? Number.parseInt(options.timeout, 10) : undefined,
            enableExecutionValidation: true,
            mockConfig,
            verbose: options.verbose,
          })

          result = pipelineResult.content

          // Log corrections if any were made
          if (
            pipelineResult.executionCorrections &&
            pipelineResult.executionCorrections.length > 0
          ) {
            console.log(
              chalk.cyan(
                `\nüîß Auto-corrected ${pipelineResult.executionCorrections.length} expectation(s) based on actual execution:`,
              ),
            )
            pipelineResult.executionCorrections.forEach((correction) => {
              console.log(
                chalk.gray(
                  `  ‚Ä¢ ${correction.testCase} - ${correction.state}: ${correction.reason}`,
                ),
              )
            })
          }

          if (pipelineResult.staticIssues.length > 0) {
            console.log(
              chalk.yellow(
                `\n‚ö†Ô∏è Note: Some static validation warnings remain (auto-correction applied where possible)`,
              ),
            )
          }
        } else {
          // Fallback to static generation without execution validation
          result = await generateTestWithAI(
            stateMachineInstance, // Pass StateMachine directly
            options.aiModel,
            options.timeout ? Number.parseInt(options.timeout, 10) : 300000,
            mockContent,
            mockPath,
            aslPath,
            outputPath,
          )
        }
        break
      }
      default:
        throw new Error(`Unknown generation type: ${type}`)
    }

    // mock„Çø„Ç§„Éó„ÅÆÂ†¥Âêà„ÅØoutputPath„ÇíË®≠ÂÆö
    if (type === 'mock') {
      outputPath =
        options.output ||
        defaultOutputPath ||
        (type === 'mock' ? DEFAULT_MOCK_FILENAME : DEFAULT_TEST_FILENAME)
    }

    safeWriteFileSync(outputPath, result)

    if (type === 'mock' && stateMachineInstance) {
      try {
        // stateMachineInstance is a StateMachine with State instances
        const dataFiles = generateTestDataFiles(stateMachineInstance, result)
        if (dataFiles.length > 0 && options.verbose) {
          console.log(
            chalk.cyan(`\nüì¶ Generated ${dataFiles.length} test data file(s) for ItemReader:`),
          )
          dataFiles.forEach((file) => {
            console.log(chalk.green(`  ‚úì ${file.path} (${file.format})`))
          })
        }
      } catch (error) {
        console.warn(chalk.yellow('‚ö†Ô∏è Could not generate test data files:', error))
      }
    }

    spinner.succeed(chalk.green(`Generated ${type} file: ${outputPath}`))
  } catch (error: unknown) {
    const errorObj = error as { message?: string }
    spinner.fail(chalk.red(`Failed to generate ${type}`))

    // ÁâπÂÆö„ÅÆ„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Çí„ÉÅ„Çß„ÉÉ„ÇØ
    if (
      errorObj.message?.includes('State machine') &&
      errorObj.message?.includes('not found in configuration')
    ) {
      console.error(chalk.red(errorObj.message))
      process.exit(1)
    }

    if (errorObj.message === 'Either --name, --asl, or --cdk option is required') {
      console.error(chalk.red(errorObj.message))
      process.exit(1)
    }

    // Claude CLI„ÇÇAPI„Ç≠„Éº„ÇÇÂà©Áî®„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÄÅ„ÉÜ„É≥„Éó„É¨„Éº„Éà„ÇíÊèê‰æõ
    if (errorObj.message?.includes('Neither Claude CLI nor ANTHROPIC_API_KEY')) {
      console.log(`\n${chalk.yellow('üí° Tip: You can use one of the following:')}`)
      console.log('1. Install Claude Code and login: https://claude.ai/code')
      console.log('2. Get an API key at: https://console.anthropic.com')
      console.log('3. Create files manually using examples in ./examples/')
      console.log('')

      // „Çµ„É≥„Éó„É´„Éï„Ç°„Ç§„É´„ÇíÁîüÊàê
      const outputPath =
        options.output || (type === 'mock' ? DEFAULT_MOCK_FILENAME : DEFAULT_TEST_FILENAME)
      let sampleContent: string

      if (type === 'mock') {
        sampleContent = `version: "1.0"
description: "Manual mock configuration template"
mocks:
  # Lambda task mock (with Payload wrapping)
  - state: "YourTaskStateName"
    type: "fixed"
    response:
      ExecutedVersion: "$LATEST"
      Payload:
        # Your Lambda function response here
        result: "success"
        data: "example"
      StatusCode: 200
  
  # Simple task mock (without Lambda)
  - state: "SimpleTask"
    type: "fixed"
    response:
      result: "processed"
  
  # Conditional mock
  - state: "ConditionalTask"
    type: "conditional"
    conditions:
      - when:
          input:
            amount: { "$gt": 100 }
        response:
          approved: true
      - default:
          approved: false
  
  # Error simulation
  - state: "ErrorTask"
    type: "error"
    error:
      type: "States.TaskFailed"
      cause: "Simulated error"`
      } else {
        sampleContent = `version: "1.0"
name: "Manual test suite template"
stateMachine: "./your-state-machine.asl.json"
baseMock: "./sfn-test.mock.yaml"

testCases:
  - name: "Success case"
    input:
      # Your test input
      userId: "test-user"
      amount: 100
    expectedOutput:
      # Expected final output
      status: "success"
    expectedPath:
      # Expected execution path
      - "FirstState"
      - "SecondState"
      - "FinalState"
  
  - name: "Error case"
    input:
      userId: "test-user"
      amount: -1
    mockOverrides:
      - state: "ValidationState"
        type: "error"
        error:
          type: "ValidationError"
          cause: "Invalid amount"
    expectedPath:
      - "FirstState"
      - "ValidationState"
      - "ErrorHandler"

settings:
  timeout: 10000
  verbose: false

assertions:
  outputMatching: "partial"
  pathMatching: "exact"`
      }

      safeWriteFileSync(outputPath, sampleContent)
      console.log(chalk.green(`\n‚úÖ Template file created: ${outputPath}`))
      console.log('Edit this file to match your state machine requirements.')
    } else {
      console.error(error)
    }
    process.exit(1)
  }
}
