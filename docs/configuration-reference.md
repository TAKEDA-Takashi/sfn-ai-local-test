# Configuration File Reference

This document provides detailed information about configuration files for sfn-ai-local-test.

## üìã Table of Contents

### Project Configuration (sfn-test.config.yaml)
1. [Project Configuration File](#project-configuration-file)
2. [stateMachines Section](#statemachines-section)
3. [paths Section](#paths-section)

### Mock Configuration File (mock.yaml)
4. [Mock File Structure](#mock-file-structure)
5. [Mock Type Specifications](#mock-type-specifications)

### Test Suite Configuration (test-suite.yaml)
6. [Test Suite Structure](#test-suite-structure)
7. [settings Section](#settings-section)
8. [assertions Section](#assertions-section)
9. [testCases Section](#testcases-section)
10. [mockOverrides Section](#mockoverrides-section)
11. [ItemReader Support](#itemreader-support)

### File Resolution Specifications
12. [Automatic File Name Inference](#automatic-file-name-inference)
13. [Path Resolution Rules](#path-resolution-rules)

## Project Configuration File

`sfn-test.config.yaml` is the file that manages the overall project settings. This file is automatically generated by the `sfn-test init` command.

### Basic Structure

```yaml
version: '1.0'                    # Required: Configuration file version

# Directory path settings (optional)
paths:
  mocks: './sfn-test/mocks'            # Storage location for mock configuration files
  testSuites: './sfn-test/test-suites' # Storage location for test suites
  testData: './sfn-test/test-data'     # Storage location for test data
  extracted: './.sfn-test/extracted'   # Save location for ASL extracted from CDK
  coverage: './.sfn-test/coverage'     # Save location for coverage reports

# State machine definition (required)
stateMachines:
  - name: 'workflow1'                   # State machine identifier
    source:
      type: 'asl'                       # For ASL JSON files
      path: './workflow1.asl.json'      # File path
      
  - name: 'workflow2'
    source:
      type: 'cdk'                       # For CDK templates
      path: './cdk.out/MyStack.template.json'
      stateMachineName: 'MyStateMachine' # Resource name (required for CDK)
```

### Configuration Item Details

| Item | Required | Description |
|------|----------|-------------|
| `version` | ‚úÖ | Configuration file version. Currently only `'1.0'` is supported |
| `paths` | ‚ùå | Directory path customization. Uses default paths if omitted |
| `stateMachines` | ‚úÖ | Array of state machine definitions. At least one is required |

## stateMachines Section

Defines the state machines managed in the project.

### For ASL JSON Format

```yaml
stateMachines:
  - name: 'payment-workflow'
    source:
      type: 'asl'
      path: './workflows/payment.asl.json'
```

### For CDK CloudFormation Format

```yaml
stateMachines:
  - name: 'order-processing'
    source:
      type: 'cdk'
      path: './cdk.out/OrderStack.template.json'
      stateMachineName: 'OrderProcessingStateMachine'
```

**Important**: Behavior when `type: 'cdk'`:
- Extracts ASL definition from CloudFormation template and **automatically saves** on first run
- Save location: `paths.extracted` directory (default: `./.sfn-test/extracted/`)
- **Smart caching**: Monitors CDK template timestamps
  - Uses cache if source hasn't been updated (fast)
  - Re-extracts and updates if source has been updated
- No need to run `extract` command beforehand (automatic processing)

### Configuration Items

| Item | Required | Description |
|------|----------|-------------|
| `name` | ‚úÖ | State machine identifier. Used when referenced from test suites |
| `source.type` | ‚úÖ | Source type. `'asl'` (ASL JSON file) or `'cdk'` (CloudFormation template) |
| `source.path` | ‚úÖ | Path to source file (relative or absolute path) |
| `source.stateMachineName` | CDK only‚úÖ | Resource name within CloudFormation template |

### Differences between ASL vs CDK Behavior

| Type | Behavior | Performance | Use Case |
|------|----------|-------------|----------|
| `asl` | Directly loads ASL JSON file | Fast (single JSON parse) | When ASL JSON file already exists |
| `cdk` | First time: Extract and save<br>Subsequent: Use cache | First time: Slightly slow<br>Subsequent: Fast | Auto-sync in CDK projects |

### Cache Mechanism

For CDK type, the following files are automatically generated:

```
.sfn-test/extracted/
‚îú‚îÄ‚îÄ workflow-name.asl.json      # Extracted ASL definition
‚îî‚îÄ‚îÄ workflow-name.metadata.json  # Metadata (timestamp, etc.)
```

**Cache update conditions**:
- When CloudFormation template is updated (mtime comparison)
- When cache file doesn't exist
- When metadata file is corrupted

### Relationship with extract Command

The `sfn-test extract` command performs the following operations:

#### Without Arguments (Recommended)
```bash
# Automatic extraction based on configuration file
sfn-test extract
```
- Extracts all CDK type state machines from `sfn-test.config.yaml`
- Saves to `paths.extracted` specified in configuration
- This is sufficient for normal CDK development

#### With Arguments (Special Cases)
```bash
# Explicitly specify path for extraction (overrides configuration)
sfn-test extract --cdk cdk.out/Stack.template.json --output ./custom/path
```
- Extracts from custom path, ignoring configuration file
- Useful for the following use cases:
  - Validating CDK templates from different environments
  - Fixed saving of specific version ASL
  - Special processing in CI/CD pipelines

#### Using Extracted ASL as Fixed
```yaml
# Reference extracted ASL file
stateMachines:
  - name: 'extracted-workflow'
    source:
      type: 'asl'  # Treat as ASL, not CDK
      path: './.sfn-test/extracted/workflow.asl.json'
```

This approach is useful when CDK templates change frequently, or when you want to fix a specific version of ASL.

### Managing Multiple State Machines

```yaml
stateMachines:
  # Direct ASL definition
  - name: 'simple-workflow'
    source:
      type: 'asl'
      path: './workflows/simple.asl.json'
      
  # ASL extracted from CDK
  - name: 'extracted-workflow'
    source:
      type: 'asl'
      path: './.sfn-test/extracted/workflow.asl.json'
      
  # Direct CDK template reference
  - name: 'cdk-workflow'
    source:
      type: 'cdk'
      path: './cdk.out/AppStack.template.json'
      stateMachineName: 'MainStateMachine'
```

## paths Section

You can customize the directory structure of your project.

### Default Paths

```yaml
# The following default paths are applied when omitted
paths:
  mocks: './sfn-test/mocks'
  testSuites: './sfn-test/test-suites'
  testData: './sfn-test/test-data'
  extracted: './.sfn-test/extracted'
  coverage: './.sfn-test/coverage'
```

### Customization Example

```yaml
# Example for monorepo structure
paths:
  mocks: './tests/mocks'
  testSuites: './tests/suites'
  testData: './tests/data'
  extracted: './build/sfn'
  coverage: './reports/coverage'
```

### Path Resolution Rules

1. **Relative paths**: Resolved as relative paths from project root
2. **Absolute paths**: Used as-is
3. **Partial specification**: Unspecified items use default values

```yaml
# Customize only mocks and testSuites
paths:
  mocks: './custom/mocks'
  testSuites: './custom/tests'
  # testData, extracted, coverage remain default
```

### Directory Roles

| Directory | Purpose | Gitignore Recommended |
|-----------|---------|----------------------|
| `mocks` | Mock configuration files (.mock.yaml) | ‚ùå |
| `testSuites` | Test suite files (test-suite.yaml) | ‚ùå |
| `testData` | Test data (CSV, JSON, etc.) | ‚ùå |
| `extracted` | ASL files extracted from CDK | ‚úÖ |
| `coverage` | Coverage reports | ‚úÖ |

## Name Resolution Mechanism

### State Machine Reference

Resolution order when referencing state machines in test suites or CLI commands:

1. **Interpret as name**: Search from `stateMachines` in `sfn-test.config.yaml`
2. **Interpret as path**: Load directly as file path

```yaml
# Example reference in test suite
stateMachine: "payment-workflow"  # Reference by name (can be omitted‚Äª)
# or
stateMachine: "./workflows/payment.asl.json"  # Direct path specification

# ‚Äª Can be omitted if file name is payment-workflow.test.yaml
```

### Automatic File Name Generation for Mocks and Test Suites

When referencing state machines by name, related files are automatically searched at the following paths:

```yaml
# sfn-test.config.yaml
stateMachines:
  - name: 'payment-workflow'
    source:
      type: 'asl'
      path: './payment.asl.json'
```

With this configuration:
- **Mock file**: `sfn-test/mocks/payment-workflow.mock.yaml`
- **Test suite**: `sfn-test/test-suites/payment-workflow.test.yaml`

```yaml
# When referencing by name in test suite
# File name: payment-workflow.test.yaml
stateMachine: "payment-workflow"  # Can be omitted (auto-inferred from file name)
baseMock: "payment-workflow"      # ‚Üí Automatically searches sfn-test/mocks/payment-workflow.mock.yaml
```

## Configuration File Examples

### Simple Project

```yaml
version: '1.0'
stateMachines:
  - name: 'main'
    source:
      type: 'asl'
      path: './workflow.asl.json'
```

### CDK Project

```yaml
version: '1.0'
stateMachines:
  - name: 'api-workflow'
    source:
      type: 'cdk'
      path: './cdk.out/ApiStack.template.json'
      stateMachineName: 'ApiWorkflowStateMachine'
  - name: 'batch-workflow'
    source:
      type: 'cdk'
      path: './cdk.out/BatchStack.template.json'
      stateMachineName: 'BatchProcessingStateMachine'
```

### Multi-Workflow Project

```yaml
version: '1.0'

paths:
  mocks: './tests/mocks'
  testSuites: './tests/suites'
  testData: './tests/fixtures'

stateMachines:
  # User management workflows
  - name: 'user-registration'
    source:
      type: 'asl'
      path: './workflows/user/registration.asl.json'
      
  - name: 'user-verification'
    source:
      type: 'asl'
      path: './workflows/user/verification.asl.json'
      
  # Order processing workflows
  - name: 'order-create'
    source:
      type: 'cdk'
      path: './cdk.out/OrderStack.template.json'
      stateMachineName: 'CreateOrderStateMachine'
      
  - name: 'order-fulfillment'
    source:
      type: 'cdk'
      path: './cdk.out/OrderStack.template.json'
      stateMachineName: 'FulfillmentStateMachine'
```

## Notes and Best Practices

### 1. Name Uniqueness

State machine `name` must be unique within the project:

```yaml
# ‚ùå Bad example: Duplicate names
stateMachines:
  - name: 'workflow'
    source:
      type: 'asl'
      path: './workflow1.asl.json'
  - name: 'workflow'  # Error: Name duplication
    source:
      type: 'asl'
      path: './workflow2.asl.json'

# ‚ùå Bad example: Missing input field in when condition
conditions:
  - when:
      age: 20        # Error: input field is required
    response:
      valid: true
    
# ‚úÖ Good example: Correct when condition syntax
conditions:
  - when:
      input:         # Required: input field must be specified
        age: 20
    response:
      valid: true
```

### 2. CDK Resource Name Verification

CDK's `stateMachineName` must match the resource name in the CloudFormation template.

You can check the CloudFormation template directly or use the following command:

```bash
# Check Step Functions resources in CloudFormation template
jq '.Resources | to_entries[] | select(.value.Type == "AWS::StepFunctions::StateMachine") | .key' cdk.out/Stack.template.json
```

### 3. Path Normalization

Relative paths are resolved as relative paths from the project root:

```yaml
# These point to the same file
path: './workflow.asl.json'
path: 'workflow.asl.json'
```

### 4. File Existence Verification

If files specified in the configuration don't exist, a runtime error will occur:

```bash
# Error example
Error: State machine source file not found: ./workflow.asl.json
```

### 5. Recommended Gitignore Settings

```gitignore
# Working directories
.sfn-test/

# CDK output (if needed)
cdk.out/

# Coverage reports (if paths are customized)
reports/coverage/
```

---

## Mock File Structure

Mock configuration files (`.mock.yaml`) define settings for simulating Step Functions state execution.

### Basic Structure

```yaml
version: "1.0"                    # Required: File version
description: "Mock description"   # Optional: Mock configuration description
mocks:                            # Required: Array of mock definitions
  - state: "StateName"            # Required: Target state name
    type: "fixed"                 # Required: Mock type
    response: { }                 # Response setting according to type
```

### Mock Definition Fields

| Field | Required | Description |
|-------|----------|-------------|
| `state` | ‚úÖ | State name to apply mock to |
| `type` | ‚úÖ | Mock type (fixed, conditional, stateful, error, itemReader) |
| `response` | ‚Äª | Response data (not needed for type: error) |
| `responseFile` | ‚Äª | Response data file path (alternative to response, type: fixed) |
| `error` | ‚Äª | Error setting (required for type: error) |
| `probability` | ‚ùå | Error occurrence probability (used with type: error, range 0-1) |
| `delay` | ‚ùå | Delay time (milliseconds, available for all mock types) |
| `conditions` | ‚Äª | Condition array (required for type: conditional, input field required for each when condition) |
| `responses` | ‚Äª | Response array (required for type: stateful) |
| `responsesFile` | ‚Äª | Response array file path (alternative to responses, type: stateful) |
| `responseFormat` | ‚ùå | Explicit file format specification (json, csv, jsonl, yaml. Usually auto-detected) |
| `data` | ‚Äª | Inline data array (for type: itemReader) |
| `dataFile` | ‚Äª | Data file path (for type: itemReader) |
| `dataFormat` | ‚ùå | Data file format (json, csv, jsonl, yaml. Usually auto-detected) |

## Mock Type Specifications

### type: "fixed" - Fixed Value Response

Simple mock that always returns the same value.

```yaml
mocks:
  - state: "ProcessData"
    type: "fixed"
    response:
      result: "success"
      data: { processed: true }
```

**Using responseFile**:
```yaml
mocks:
  - state: "LoadData"
    type: "fixed"
    responseFile: "data.json"  # Load from test-data directory
```

### type: "conditional" - Conditional Response

Returns different responses based on input.

```yaml
mocks:
  - state: "ValidateAge"
    type: "conditional"
    conditions:
      - when:
          input:
            age: 20               # Partial match condition
            category: "adult"
        response:
          valid: true
      - when:
          input:
            age: 15               # Another condition
        response:
          valid: false
      - default:                  # When no conditions match
          error: "Invalid input"
```

**Condition Matching Mechanism**:
- **input field required**: All `when` conditions must specify `input:` field
- **Partial match**: Condition is met if all fields in `when.input` are present in actual input with matching values
- **Additional fields allowed**: Input can have additional fields without issues
- **No exact match required**: Only checks fields specified in condition

**Example**:
```yaml
# Condition
when:
  input:
    userId: "123"
    status: "active"

# All these inputs match
input: { userId: "123", status: "active" }                    # ‚úÖ Exact match
input: { userId: "123", status: "active", extra: "data" }     # ‚úÖ Additional fields OK
input: { userId: "123", status: "active", nested: {...} }     # ‚úÖ Nested data also OK

# These don't match
input: { userId: "456", status: "active" }     # ‚ùå userId mismatch
input: { userId: "123" }                       # ‚ùå status missing
```

### type: "stateful" - Stateful Response

Returns different responses based on call count. After reaching the end of the array, it loops back to the beginning.

```yaml
mocks:
  - state: "RetryableTask"
    type: "stateful"
    responses:
      - { error: "Temporary failure" }    # 1st call
      - { error: "Still failing" }        # 2nd call
      - { success: true, data: "OK" }     # 3rd call (4th and beyond loop back to 1st)
```

**Using responsesFile**:
```yaml
mocks:
  - state: "ProgressTracker"
    type: "stateful"
    responsesFile: "progress-states.json"  # Load from test-data directory
```

**responsesFile Format Examples (JSON)**:
```json
[
  { "status": "starting", "progress": 0 },
  { "status": "processing", "progress": 50 },
  { "status": "completed", "progress": 100 }
]
```

**responsesFile Format Examples (JSONL)**:
```jsonl
{"status": "starting", "progress": 0}
{"status": "processing", "progress": 50}
{"status": "completed", "progress": 100}
```

### type: "error" - Error Generation

Generates Step Functions errors. When `probability` is specified and error doesn't occur, returns empty object `{}`.

```yaml
mocks:
  - state: "ExternalAPI"
    type: "error"
    error:
      type: "States.TaskFailed"       # Error type
      cause: "External service down"   # Error cause
      message: "Connection timeout"    # Error message (optional)
    probability: 0.5                  # Error probability (optional, 0-1 range. Always errors if omitted)
                                      # Returns {} if error doesn't occur
```

**Standard Error Types**:
- `States.ALL`: All errors
- `States.TaskFailed`: Task failure
- `States.Permissions`: Permission error
- `States.Timeout`: Timeout
- `States.DataLimitExceeded`: Data size exceeded
- `Lambda.ServiceException`: Lambda service error
- `Lambda.TooManyRequestsException`: Rate limiting

### Delay Field

All mock types can use the `delay` field to delay responses. This simulates latency of actual APIs or services.

```yaml
mocks:
  # Delay in Fixed type mock
  - state: "GetUserData"
    type: "fixed"
    delay: 1000  # 1 second delay
    response:
      userId: "12345"

  # Delay in Error type mock (delay before throwing error)
  - state: "APICall"
    type: "error"
    delay: 2000  # Error after 2 seconds
    error:
      type: "States.TaskFailed"
      cause: "Timeout"

  # Delay in Conditional type mock
  - state: "ProcessOrder"
    type: "conditional"
    delay: 500  # Default 500ms delay
    conditions:
      - when:
          input:
            priority: "high"
        delay: 100  # High priority has 100ms delay (overrides mock-level setting)
        response:
          status: "processed"
      - when:
          input:
            priority: "low"
        delay: 3000  # Low priority has 3 second delay
        response:
          status: "queued"
```

**Note**: In Conditional type mocks, condition-level `delay` takes precedence over mock-level `delay`.

### type: "itemReader" - Data Source for Distributed Map

Dedicated type for mocking ItemReader in Distributed Map states. Provides data that would be read from external resources (S3, DynamoDB, etc.).

```yaml
mocks:
  # Inline data
  - state: "ProcessUsersMap"
    type: "itemReader"
    data:
      - { id: 1, name: "Alice", email: "alice@example.com" }
      - { id: 2, name: "Bob", email: "bob@example.com" }
      - { id: 3, name: "Charlie", email: "charlie@example.com" }

  # Load data from file
  - state: "ProcessOrdersMap"
    type: "itemReader"
    dataFile: "orders.json"     # Load from test-data directory
    
  # Using CSV file
  - state: "ProcessRecordsMap"
    type: "itemReader"
    dataFile: "records.csv"     # Auto-detect from extension
    
  # Explicit format specification (usually not needed)
  - state: "ProcessDataMap"
    type: "itemReader"
    dataFile: "data.txt"
    dataFormat: "jsonl"         # Specify when can't determine from file extension
```

**Difference between ItemReader and regular Map (ItemsPath)**:
- **ItemReader**: Reads data from external resources ‚Üí Mock needed
- **ItemsPath**: Gets array from input data ‚Üí No mock needed (controlled by input)

**dataFile Format Examples**:

JSON format:
```json
[
  { "id": 1, "value": 100 },
  { "id": 2, "value": 200 }
]
```

CSV format:
```csv
id,name,amount
1,Product A,100
2,Product B,200
```

JSONL format:
```jsonl
{"id": 1, "status": "pending"}
{"id": 2, "status": "processing"}
{"id": 3, "status": "completed"}
```

---

## Test Suite Structure

Test suite files (`test-suite.yaml`) define test cases for Step Functions workflows.

### Basic Structure

```yaml
version: "1.0"                    # Required: Configuration file version
name: "Test Suite Name"           # Required: Test suite name
description: "Description"        # Optional: Test suite description
stateMachine: "workflow-name"    # Required‚Äª: State machine name or path (‚Äª auto-inferred from file name)
baseMock: "mock-name"            # Optional: Mock configuration (name or path, auto-inferred from state machine name if omitted)

settings: { }                     # Optional: Execution settings
assertions: { }                   # Optional: Assertion settings
testCases: [ ]                    # Required: Array of test cases
```

## settings Section

Settings that control test execution behavior.

### Configuration Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `timeout` | number | 10000 | **Overall default timeout (milliseconds)**<br>Maximum execution time for each test case. Can be overridden by individual test cases. |
| `parallel` | boolean | false | **Parallel execution mode**<br>`true`: Execute all test cases simultaneously<br>`false`: Execute sequentially |
| `verbose` | boolean | false | **Verbose log output**<br>`true`: Output detailed execution information<br>`false`: Minimal output |
| `stopOnFailure` | boolean | false | **Early termination of test suite**<br>`true`: Skip remaining tests after first test case failure<br>`false`: Execute all test cases even if failures occur<br>‚Äª Does not affect state execution within individual tests |

### Usage Examples

```yaml
settings:
  timeout: 10000           # 10 second timeout
  parallel: false          # Sequential execution
  verbose: true            # Detailed log output
  stopOnFailure: false     # Continue on failure
```

### Execution Mode Differences

#### Parallel Execution (`parallel: true`)
```
Test1 ‚îÄ‚îÄ‚îê
Test2 ‚îÄ‚îÄ‚îº‚îÄ‚îÄ Simultaneous ‚îÄ‚îÄ> Result
Test3 ‚îÄ‚îÄ‚îò
```
- **Benefits**: Fast execution
- **Drawbacks**: Difficult debugging, potential resource conflicts

#### Sequential Execution (`parallel: false`)
```
Test1 ‚îÄ‚îÄ> Test2 ‚îÄ‚îÄ> Test3 ‚îÄ‚îÄ> Result
```
- **Benefits**: Easy debugging, simple error identification
- **Drawbacks**: Longer execution time

#### stopOnFailure Behavior
`stopOnFailure` controls **inter-test case** behavior:

```yaml
# stopOnFailure: false (default)
TestCase1: ‚úÖ Pass
TestCase2: ‚ùå Fail (error at Task3) ‚Üí TestCase3 still executes
TestCase3: ‚úÖ Pass
TestCase4: ‚ùå Fail ‚Üí All tests complete

# stopOnFailure: true
TestCase1: ‚úÖ Pass  
TestCase2: ‚ùå Fail (error at Task3) ‚Üí Stop here
TestCase3: ‚è≠Ô∏è Skip (not executed)
TestCase4: ‚è≠Ô∏è Skip (not executed)
```

**Note**: State machine execution within each test case behaves normally. When a task errors:
- If Catch exists, processing continues
- If no Catch, that test case fails and ends
- Whether to proceed to next test case depends on `stopOnFailure`

## assertions Section

Settings that control test result verification methods.

### Configuration Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `outputMatching` | string | "exact" | **Output comparison method** (exact, partial) |
| `pathMatching` | string | "exact" | **Execution path comparison method** (exact, includes, sequence) |
| `stateMatching` | string | "exact" | **State verification comparison method** (exact, partial) |

### outputMatching Details

#### `"exact"` - Exact Match
Expected output and actual output must match completely.

#### `"partial"` - Partial Match
OK if expected output fields are included in actual output. Additional fields are ignored.

### pathMatching Details

#### `"exact"` - Exact Match
Path must match completely including order.

**Map/Distributed Map State Handling**:
Map and Distributed Map states themselves are recorded in the execution path, but individual iteration states executed internally are not recorded. Use dedicated fields (`mapExpectations`, `parallelExpectations`) for detailed verification of Map/Parallel states.

```yaml
# State machine structure:
# Start -> ProcessMap (Map) -> End
#           ‚îî‚îÄ> InnerTask (executed for each item)

# Execution path example:
expectedPath: ["Start", "ProcessMap", "End"]
# Note: "InnerTask" is not included in execution path
```

### expectedPath - Multiple Condition Specification

`expectedPath` can specify not only single path conditions but also multiple path conditions. When multiple are specified, all conditions must be satisfied (AND condition).

#### Single Condition
```yaml
expectedPath: ["Start", "Process", "End"]  # Exact match with this path
```

#### Multiple Conditions (AND condition, effective in sequence mode)
```yaml
# In sequence mode, verify that all sequences are included
assertions:
  pathMatching: "sequence"  # Each condition evaluated as sequence
expectedPath:
  - ["Task1", "Task2"]     # Task1‚ÜíTask2 exists consecutively
  - ["Task3", "Task4"]     # AND Task3‚ÜíTask4 also exists consecutively
  # Both sequences must be included in execution path
```

#### Practical Example: Complex Flow Verification
```yaml
testCases:
  - name: "Complex branch flow test"
    input: { type: "complex" }
    assertions:
      pathMatching: "sequence"
    expectedPath:
      # Initial processing executed
      - ["Initialize", "Validate"]
      # Main processing executed
      - ["ProcessMain", "Transform", "Store"]
      # Post-processing executed
      - ["Cleanup", "Notify"]
    # Verifies all these sequences are included in order
```

#### `"includes"` - Elements Included
OK if all expected states are included (order doesn't matter).

```yaml
# Example:
expectedPath: ["Task2", "Task3"]
actualPath: ["Task1", "Task2", "Task3", "Task4"]  # ‚úÖ OK - Both Task2 and Task3 included
actualPath: ["Task1", "Task3", "Task2", "Task4"]  # ‚úÖ OK - Different order but both included
actualPath: ["Task3", "Task1", "Task2", "Task4"]  # ‚úÖ OK - Different order but both included
actualPath: ["Task1", "Task2", "Task4", "Task5"]  # ‚ùå NG - Task3 not included
```

#### `"sequence"` - Consecutive Sequence
OK if expected states are included in consecutive order.

```yaml
# Example:
expectedPath: ["Task2", "Task3"]
actualPath: ["Task1", "Task2", "Task3", "Task4"]  # ‚úÖ OK - Task2‚ÜíTask3 consecutive
actualPath: ["Task2", "Task3", "Task1", "Task4"]  # ‚úÖ OK - Task2‚ÜíTask3 consecutive
actualPath: ["Task1", "Task3", "Task2", "Task4"]  # ‚ùå NG - Task2‚ÜíTask3 order wrong
actualPath: ["Task2", "Task1", "Task3", "Task4"]  # ‚ùå NG - Task2 and Task3 not consecutive
```

### stateMatching Details

#### `"exact"` - Exact Match
State input/output and variables must match exactly.

#### `"partial"` - Partial Match
OK if expected value fields are included in actual values. Additional fields ignored.

### Usage Examples

```yaml
assertions:
  outputMatching: "partial"      # Partial match verification
  pathMatching: "exact"          # Path exact match
  stateMatching: "partial"       # State verification partial match
```

## testCases Section

Configuration for individual test cases.

### Test Case Options

| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `name` | string | ‚úÖ | Test case name |
| `description` | string | ‚ùå | Test case description |
| `input` | any | ‚úÖ | Input to state machine |
| `expectedOutput` | any | ‚ùå | Expected output |
| `expectedPath` | string[] \| string[][] | ‚ùå | Expected execution path (multiple conditions possible) |
| `expectedError` | object/string | ‚ùå | Expected error |
| `stateExpectations` | StateExpectation[] | ‚ùå | State-level verification |
| `timeout` | number | ‚ùå | Timeout for this test case |
| `skip` | boolean | ‚ùå | Skip test |
| `only` | boolean | ‚ùå | Execute only this test |
| `mockOverrides` | MockOverride[] | ‚ùå | Test-specific mock settings |
| `mapExpectations` | MapExpectation[] | ‚ùå | Map state specific verification |
| `parallelExpectations` | ParallelExpectation[] | ‚ùå | Parallel state specific verification |

### stateExpectations - State-Level Verification

Can verify input/output and variables of individual states.

#### Basic Structure
```yaml
stateExpectations:
  - state: "ProcessData"        # State name
    input: { data: "raw" }       # Expected input
    output: { data: "processed" } # Expected output
    variables:                   # Expected variable values (after execution)
      counter: 1
      status: "active"
```

#### Dot Notation and Bracket Notation
For specifying internal states of Map/Parallel:

```yaml
stateExpectations:
  # Dot notation
  - state: "MapState.0"           # 0th iteration
    input: { item: 1 }
    output: { result: 2 }
    
  - state: "MapState.0.InnerTask" # Internal state
    output: { processed: true }
    
  # Bracket notation
  - state: "MapState[2]"          # 2nd iteration
    input: { item: 3 }
    
  # Mixed notation
  - state: "MapState[0].InnerTask"
    output: { success: true }
    
  # Parallel state
  - state: "ParallelProcess[0]"   # Branch 0
    output: { branchResult: "A" }
    
  - state: "ParallelProcess[1].SubTask"  # Internal state of Branch 1
    input: { branchData: "B" }
```

#### Partial Verification
For large data, verify only specific indices:

```yaml
stateExpectations:
  # Overall Map input/output
  - state: "ProcessLargeData"
    input: { items: [/* 1000 items */] }
    output: { processedCount: 1000 }
    
  # Check only specific indices
  - state: "ProcessLargeData[0]"    # First
    output: { index: 0, success: true }
    
  - state: "ProcessLargeData[999]"  # Last
    output: { index: 999, success: true }
    
  # Skip middle (efficient verification)
```

#### Variable Verification
Verify variables set by Assign state:

```yaml
stateExpectations:
  - state: "SetVariables"
    variables:               # Variable values after this state execution
      userId: "12345"
      timestamp: 1234567890
      
  - state: "UseVariables"
    input:                   # Whether variables are reflected in input
      user: "12345"
      time: 1234567890
```

### mapExpectations - Map State Specific Verification

Verifies Map state execution flow (iteration count, execution path of each iteration).

#### Basic Structure
```yaml
mapExpectations:
  - state: "ProcessItems"            # Map state name
    iterationCount: 5                # Expected iteration count
    iterationPaths:                  # Iteration path verification
      pathMatching: "exact"           # Path comparison method (exact, includes, sequence)
      # all and samples used independently (can be used together but be careful)
      all:                            # Path all iterations take (only for common paths)
        - "ValidateItem"
        - "TransformItem"  
        - "SaveItem"
      # or
      samples:                        # Specific iteration paths (individual verification)
        0: ["ValidateItem", "TransformItem", "SaveItem"]  # First
        4: ["ValidateItem", "HandleError", "SaveItem"]    # Last (via error handling)
```

#### Usage Example 1: Iteration Count Verification
```yaml
# Verify matches input array length
mapExpectations:
  - state: "ProcessArray"
    iterationCount: 10    # Verify 10 items are processed
```

#### Usage Example 2: Common Path Verification for All Iterations
```yaml
mapExpectations:
  - state: "MapState"
    iterationPaths:
      pathMatching: "sequence"  # Guarantee order
      all: ["Validate", "Process"]  # All execute in this order
```

#### Usage Example 3: Individual Path Verification (Error handling, etc.)
```yaml
mapExpectations:
  - state: "ProcessWithErrors"
    iterationCount: 3
    iterationPaths:
      # Don't specify all (paths are not uniform)
      samples:  # Verify each iteration individually
        0: ["Task", "Success"]      # First succeeds
        1: ["Task", "ErrorHandler"] # Second has error
        2: ["Task", "Success"]      # Third succeeds
```

#### Usage Example 4: Combination of Common and Specific Paths
```yaml
mapExpectations:
  - state: "ProcessWithValidation"
    iterationPaths:
      pathMatching: "includes"  # Verify with partial match
      all: ["ValidateItem"]     # All include validation step
      samples:
        0: ["ValidateItem", "TransformItem", "SaveItem"]  # Also check detailed path
```

### parallelExpectations - Parallel State Specific Verification

Verifies Parallel state execution flow (branch count, execution path of each branch).

#### Basic Structure
```yaml
parallelExpectations:
  - state: "ParallelProcessing"      # Parallel state name
    branchCount: 3                   # Expected branch count
    branchPaths:                     # Each branch path verification
      pathMatching: "exact"           # Path comparison method
      0: ["BranchA_Task1", "BranchA_Task2"]  # Branch 0 path
      1: ["BranchB_Task1", "BranchB_Task2"]  # Branch 1 path
      2: ["BranchC_Task1", "BranchC_Task2"]  # Branch 2 path
```

#### Usage Example 1: Branch Count Verification
```yaml
parallelExpectations:
  - state: "ParallelValidation"
    branchCount: 2    # 2 branches execute in parallel
```

#### Usage Example 2: Each Branch Execution Path Verification
```yaml
parallelExpectations:
  - state: "DataProcessing"
    branchPaths:
      pathMatching: "includes"   # Partial match
      0: ["ValidateData"]        # Branch 0 includes validation
      1: ["TransformData"]       # Branch 1 includes transformation
      2: ["StoreData"]           # Branch 2 includes storage
```

#### Usage Example 3: Branches with Conditional Logic
```yaml
parallelExpectations:
  - state: "ComplexParallel"
    branchPaths:
      pathMatching: "sequence"
      0: ["Check", "ProcessA"]    # Condition-dependent path
      1: ["Check", "ProcessB"]    # Different condition path
```

### Map/Parallel Verification Usage

| Verification Item | stateExpectations | mapExpectations | parallelExpectations |
|-------------------|------------------|-----------------|---------------------|
| **Individual Data Verification** | ‚úÖ Detailed input/output, variable verification | ‚ùå | ‚ùå |
| **Execution Flow Verification** | ‚ùå | ‚úÖ Iteration control flow | ‚úÖ Branch control flow |
| **Count Verification** | ‚ùå | ‚úÖ Iteration count | ‚úÖ Branch count |
| **Path Verification** | ‚ùå | ‚úÖ Each iteration path | ‚úÖ Each branch path |

#### Combination Example
```yaml
# Verify both data and flow
testCases:
  - name: "Complete Map verification"
    input: { items: [1, 2, 3] }
    
    # Data verification (specific iteration)
    stateExpectations:
      - state: "ProcessMap[0]"
        input: { item: 1 }
        output: { result: 2 }
    
    # Flow verification (overall)
    mapExpectations:
      - state: "ProcessMap"
        iterationCount: 3
        iterationPaths:
          all: ["Double", "Save"]
```

### skip and only Usage

```yaml
testCases:
  - name: "Normal test"
    input: { }
    
  - name: "Temporarily disabled"
    skip: true              # This test is skipped
    input: { }
    
  - name: "Test under debug"
    only: true              # Only this test is executed
    input: { }
```

### expectedError Details

Error expectation can be specified as string or object.

```yaml
testCases:
  # String specification (error type only)
  - name: "Error test 1"
    input: { invalid: true }
    expectedError: "ValidationError"
  
  # Object detailed specification
  - name: "Error test 2"
    input: { invalid: true }
    expectedError:
      type: "ValidationError"
      cause: "Invalid input format"
      message: "Validation failed"
```

## mockOverrides Section

Test case specific mock settings that override base mocks.

### Mock Types

#### `type: "fixed"` - Fixed Value
```yaml
mockOverrides:
  - state: "ProcessData"
    type: "fixed"
    response:
      result: "processed"
      status: "success"
```

#### `type: "conditional"` - Conditional
```yaml
mockOverrides:
  - state: "ValidateInput"
    type: "conditional"
    conditions:
      - when:
          input:
            age: 20  # Partial match condition
        response:
          valid: true
          category: "adult"
      - default:
          valid: false
```

#### `type: "stateful"` - Stateful (Changes with call count)
```yaml
mockOverrides:
  - state: "RetryableTask"
    type: "stateful"
    responses:
      - { error: "Temporary failure" }  # 1st call
      - { error: "Still failing" }      # 2nd call
      - { success: true, data: "OK" }   # 3rd call (4th and beyond loop)
```

#### `type: "error"` - Error Generation
```yaml
mockOverrides:
  - state: "ExternalAPI"
    type: "error"
    error:
      type: "ServiceException"
      cause: "External service is down"
```

#### `type: "itemReader"` - Data Source for Distributed Map
```yaml
mockOverrides:
  - state: "ProcessBatchMap"
    type: "itemReader"
    data:
      - { batchId: 1, status: "pending" }
      - { batchId: 2, status: "processing" }
```

## File Path Resolution Rules

File path resolution rules when specifying file paths in mock files:

1. **Simple file names/paths** (`items.csv`, `subdir/items.csv`)
   - Resolved based on `sfn-test/test-data/` directory
   - Subdirectories also automatically reference within test-data

2. **Explicit relative paths** (`./data/items.csv`, `../shared/data.json`)
   - Only when starting with `./` or `../`
   - Resolved as relative paths from project root

3. **Absolute paths** (`/absolute/path/to/file.csv`)
   - Used as-is

## Complete Configuration Example

```yaml
version: "1.0"
name: "Comprehensive Test Suite"
description: "All configuration options example"
stateMachine: "workflow"  # Name resolution from sfn-test.config.yaml
baseMock: "workflow"      # Auto-resolve sfn-test/mocks/workflow.mock.yaml

# Execution settings
settings:
  timeout: 10000           # 10 second default timeout
  parallel: false          # Sequential execution for easier debugging
  verbose: true            # Detailed log output
  stopOnFailure: false     # Execute all tests

# Verification settings
assertions:
  outputMatching: "partial"      # Partial match (verify only required items)
  pathMatching: "exact"          # Strict path verification

# Test cases
testCases:
  # Basic test
  - name: "Normal flow"
    description: "Standard execution path"
    input:
      userId: "user123"
      amount: 100
    expectedOutput:
      status: "completed"
      userId: "user123"
    expectedPath:
      - "ValidateInput"
      - "ProcessPayment"
      - "SendNotification"

  # Test with timeout setting
  - name: "Slow process test"
    input:
      processType: "heavy"
    timeout: 20000         # 20 seconds for this test only
    mockOverrides:
      - state: "HeavyProcess"
        type: "fixed"
        delay: 5000   # 5 second delay
        response:
          result: "completed"

  # Error case
  - name: "Error handling"
    input:
      userId: "invalid"
    expectedError:
      type: "ValidationError"
      cause: "User not found"
    mockOverrides:
      - state: "ValidateUser"
        type: "error"
        error:
          type: "ValidationError"
          cause: "User not found"

  # Debug use (temporary skip)
  - name: "Work in progress"
    skip: true             # Temporarily skip during development
    input:
      experimental: true
```

## CLI Command Reference

### sfn-test extract

Extract Step Functions state machines from CDK/CloudFormation templates.

```bash
sfn-test extract [options]
```

#### Options

| Option | Description |
|--------|-------------|
| `-c, --cdk <path>` | Path to CDK synth output file |
| `-d, --cdk-out <dir>` | CDK output directory path (e.g., cdk.out) |
| `--cdk-state-machine <id>` | Logical ID of state machine in CDK template |
| `-o, --output <dir>` | Output directory for extracted files (default: ./.sfn-test/extracted) |
| `--name <name>` | Extract specific state machine from config by name |

#### Examples

```bash
# Using configuration file
sfn-test extract

# Extract from specific CDK output
sfn-test extract --cdk cdk.out/MyStack.template.json

# Extract from CDK directory with specific state machine
sfn-test extract --cdk-out cdk.out --cdk-state-machine OrderProcessing

# Extract to custom directory
sfn-test extract --output ./extracted-asls
```

### sfn-test generate

Generate mock or test files using AI assistance.

```bash
sfn-test generate <type> [options]
```

#### Arguments

- `type`: Either `mock` or `test`

#### Options

| Option | Description | Default |
|--------|-------------|---------|
| `-n, --name <name>` | State machine name from configuration | - |
| `-a, --asl <path>` | Path to ASL JSON file | - |
| `-c, --cdk <path>` | Path to CDK synth output | - |
| `--cdk-state-machine <name>` | Logical ID of state machine in CDK template | - |
| `-o, --output <path>` | Output file path | Auto-generated |
| `-m, --mock <path>` | Path to mock file (for test generation) | - |
| `--ai-model <model>` | AI model to use | claude-sonnet-4-20250522 |
| `--timeout <ms>` | AI generation timeout in milliseconds | 60000 + complexity-based |
| `--max-attempts <number>` | Maximum generation attempts with validation feedback | 2 |
| `--concurrency <number>` | Maximum concurrent AI operations | 1 |
| `--verbose` | Enable verbose output during generation | false |

#### Examples

```bash
# Generate mock using configuration
sfn-test generate mock --name order-processing

# Generate mock from ASL file
sfn-test generate mock --asl ./workflow.asl.json -o ./mock.yaml

# Generate test with retry attempts
sfn-test generate test --name order-processing --max-attempts 3

# Generate with custom AI model
sfn-test generate mock --name workflow --ai-model claude-sonnet
```

### sfn-test run

Run state machine tests or test suites.

```bash
sfn-test run [options]
```

#### Options

| Option | Description | Default |
|--------|-------------|---------|
| `-n, --name <name>` | State machine name from configuration | - |
| `-a, --asl <path>` | Path to ASL JSON file | - |
| `-c, --cdk <path>` | Path to CDK synth output | - |
| `--cdk-state-machine <name>` | Logical ID of state machine in CDK template | - |
| `-m, --mock <path>` | Path to mock configuration file | - |
| `-i, --input <json>` | Input JSON for the state machine | - |
| `-s, --suite <path>` | Path to test suite YAML file | - |
| `-r, --reporter <type>` | Test reporter (default\|json\|junit) | default |
| `-o, --output <path>` | Output file path (for json/junit reporters) | - |
| `--bail` | Stop on first failure | false |
| `--verbose` | Enable verbose output | false |
| `--quiet` | Minimal output | false |
| `--cov [format]` | Show coverage after execution. Format: text (default when flag is used)\|json\|html. Without this flag, no coverage is displayed. | - |

#### Examples

```bash
# Run all tests
sfn-test run

# Run specific state machine tests
sfn-test run --name order-processing

# Run with coverage (text format by default)
sfn-test run --cov

# Run with coverage in specific format
sfn-test run --cov json
sfn-test run --cov html

# Run specific test suite with JSON reporter
sfn-test run --suite ./test-suite.yaml --reporter json -o results.json

# Run with direct ASL and mock
sfn-test run --asl ./workflow.asl.json --mock ./mock.yaml --input '{"id": 123}'
```

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `ANTHROPIC_API_KEY` | Claude API key (not required in Claude Code environment) | - |
| `DEBUG_OUTPUT_PATH` | Enable detailed mock matching logs | false |
| `AI_MODEL` | Default AI model for generation | claude-sonnet-4-20250522 |
